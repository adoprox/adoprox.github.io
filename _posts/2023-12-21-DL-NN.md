---
layout: post
title: "Image segmentation using DL"
description: null
image: assets/images/feature.jpg
nav-menu: true
---

<font size="6"><p>The following papers were used as a starting point to understand the nature of dataset. Moreover where the data is coming from and the purpose to automate its segmentation</p></font>

[Paper 1][PAPER 1] [Paper 2][PAPER 2]

[PAPER 1]: https://www.sciencedirect.com/science/article/abs/pii/S0378775318301459?via%3Dihub
[PAPER 2]: https://www.sciencedirect.com/science/article/abs/pii/S0378775317308182?via%3Dihub

<font size="6"><p>We technically used 2 datasets of the same nature i.e they were obtained using the same techniques. The key difference in the datasets were the spatial resolution, the number of classes and the availability of labelled data. The last difference is vital to building this solution as generating labelled tomographic X-ray data is labour-intensive and error prone. For the second dataset we manually labelled 4 images to conduct the training, validation and testing. </p></font>

<font size="6"><p>In this post we will go through the very basics and the thought process behind the work. More technical exploration can be done using my Github linked below. For this project we used 2 models VGGNet (figure 1) and UNET (figure 2). To set some context we need to understand how semantic segmentation works wrt NN, 2 processes are required for it to happen, namely feature extraction and then classification. In VGGNet feature extraction and classification is done separately, but in UNET both processes are part of one architecture. </p></font>

![VGGNet architecture]({{site.baseurl}}/assets/images/VGGNet.jpg)
**Figure 1: VGGNet architecture** 
![Unet architecute]({{site.baseurl}}/assets/images/unet_1.jpg)
**Figure 2: UNET architecture**

<p><font size=6>I worked on the UNET model for this task. First I thought of making my own model XD but that was a little far fetched, instead using UNET was bit of a learning curve too. Coming to the architecture the UNET follows a encoder-decoder architecture, the beauty of it is that during encoding phases skip connections are used to reconstruct the images. This architecture first focuses on feature extraction and at each step pooling and convolution operations lower the spatial dimension increasing the feature maps. It was interesting to observe these masks and feature each neuron had learned. During reconstruction it uses those skip connections from previous corresponding layers to reconstruct the spatial resolution of the image back.</p></font>

<p><font size=6>